---
layout: post
title:  "Proxyを使用したブラックリストの構築"
date:   2019-02-03
excerpt: "Proxyにブラックリストの設定し、アクセス制限をかける"
project: true
tag:
- ubuntu
- システム
comments: false
---

# Proxyを使用したブラックリストの構築
## 構築する理由
### アクセスを制限できる
ブラックリストに特定のドメインや、URLを設定してそのサイトへのアクセスを制限し、アダルトサイトや悪質なサイトへ制限をかけ、会社へのリスクを事前に最小限にする

## 設定
### 手順
そもそもなんだけど、ブラックリストにはドメインを指定してアクセスを制限する方法と<br>
URLを直接指定して制限をする2つの種類があります<br>

■https://■
いま主流になっているhttpsから始まるリンクは、プロキシ上ドメインとポート番号しか設定できません<br>
そのためドメインを指定して制限する必要があります<br>

■http://■
地道に残り続ける、httpちゃんがあるのでこちらはURLを直接指定してアクセスを制限するよ<br>

ドメインでどーんと制限したい場合は、ドメインだけでいいけどそうするとまるっとそのドメイン関連のページにアクセスできなくなるので<br>
業務などで不都合が出る可能性があるわ<br>
その場合は、URLをこまごまと設定していくのよ<br>

1.  ブラックリストのドメイン制限ファイル作成するよ！<br>

```
/etc/squid/
sudo vim blacklist.txt
```

2.  ファイルの中にアクセスを制限したいドメインを記載するよ<br>

```
www.yahoo.com
www.bing.com
```
ここで重複したドメインを記載するとエラーがくるよ！<br>
必ず、重複しないように記載をする必要があるよ<br>

3.  つぎはURLを指定して制限したいファイルを作成するよ<br>

```
/etc/squid/
sudo vim blacklist_regex
```

4.  ファイルの中にアクセスを制限したいURLを記載するよ<br>

```
^http://www.yahoo.com/
^http://www.bing.com/
```
このとき必ず[正規表現](https://www.mnet.ne.jp/~nakama/)で記載するよお<br>

5.  `squid.conf`にblacklistの記述を追加する<br>

```
acl blacklist dstdomain "/etc/squid/blacklist.txt"
acl blacklist dstdomain "/etc/squid/blacklist.regex"
http_access deny blacklist
http_access allow localnet
http_access allow localhost
http_access deny all
```

6.  Squidをリロードしてステータスを確認する<br>

```
/etc/squid/
sudo systemctl reload squid
sudo systemctl status squid
```
ここでエラーもワーニングもなく、runningになってたらOK

## 確認
### 手順
リストを設定したのでwgetでドメインやURLを指定してアクセスできないか確認する<br>
1.  とりあえず、ブラックリストに登録していない適当なサイトをwgetしてみる<br>

```
wget http://www.mnet.ne.jp/~nakama/
```
こんなのかえってくる<br>

```
--2019-04-09 08:43:19--  http://www.mnet.ne.jp/~nakama/
Connecting to 10.0.2.15:8080... connected.
Proxy request sent, awaiting response... 200 OK
Length: 54603 (53K) [text/html]
Saving to: ‘index.html.7’

index.html.7                          100%[======================================================================>]  53.32K  --.-KB/s    in 0.1s    

2019-04-09 08:43:20 (419 KB/s) - ‘index.html.7’ saved [54603/54603]
```
このサイトは制限されていないみたい

2.  さっそくブラックリストに登録したドメインへアクセスしてみる
```
wget www.yahoo.com
```
こんなのが帰ってくる<br>
```
--2019-04-09 08:44:58--  http://www.yahoo.com/
Connecting to 10.0.2.15:8080... connected.
Proxy request sent, awaiting response... 403 Forbidden
2019-04-09 08:44:58 ERROR 403: Forbidden.

```
ここで大事なの`403 Forbidden`これ！このHTTPステータスコード<br>
[参考リンク](https://ja.wikipedia.org/wiki/HTTP%E3%82%B9%E3%83%86%E3%83%BC%E3%82%BF%E3%82%B9%E3%82%B3%E3%83%BC%E3%83%89)<br>

`403 Forbidden`<br>
禁止されている。リソースにアクセスすることを拒否された。リクエストはしたが処理できないという意味<br>
アクセス権がない場合や、ホストがアクセス禁止処分を受けた場合などに返される。<br>
<br>
HTTPステータすコードが思った通りに帰ってくればOK